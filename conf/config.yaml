make_dataset:
  masterdb_path: data/raw/masterdbFromRobMac.xlsx
  mac_path: data/raw/mcmaster-database-de-identified-comments.xlsx
  sas_path: data/raw/sask-database-de-identified-comments.xlsx
  output_path: data/interim/masterdbForNLP.xlsx
  q1_condense: True
  q1_condense_col_name: Q1c
  q2_invert: True
  q2_invert_col_name: Q2i
  q3_invert: True
  q3_invert_col_name: Q3i
  qual_condense: True
  qual_condense_col_name: QUALc
  text_var: comment

proc_spacy:
  dataset_path: ${make_dataset.output_path}
  output_path: data/interim/masterdbForNLPSpacyProc.pkl
  text_var: comment
  spacy_model: en_core_web_sm
  spacy_procs: 4
  progress_bar: True

split_train_test:
  dataset_path: ${proc_spacy.output_path}
  output_dir: data/processed
  train_path: ${split_train_test.output_dir}/train.pkl
  test_path: ${split_train_test.output_dir}/test.pkl
  test_size: 0.2
  random_state: 43
  train_file_name: train.pkl
  test_file_name: test.pkl

train:
  # input/output configuration
  mlflow_dir: mlruns
  conda_yaml_path: './conda.yaml'
  mlflow_tracking_dir: ./mlruns
  mlflow_experiment_name: ${train.target_var}_manual
  train_path: ${split_train_test.train_path}
  text_var: comment
  random_seed: 43
  # text_var: ${proc_spacy.text_var}_spacy

  # target variable options
  target_var: QUAL
  invert_target: False
  qual_exclude_level4: False

  # spacy-specific processing options
  spacy_prog: True
  spacy_procs: 12

  # cross-validation options
  cv_folds: 5
  
  # augmentation options
  do_aug: True
  aug_factor: 1.0 # float, the multiplier for the whole dataset
  match_factor: 0.25 # float, the fraction of the most frequent class that the rarer classes are upsampled to
  
  # hyperparams
  punct: True
  pron: True
  stop: False
  lemma: False
  ngram_min: 1
  ngram_max: 2
  max_df: 1.0
  min_df: 1
  token_count: True
  pos_counts: False
  ent_counts: False
  vectors: False
  model_c: 0.01
  max_iter: 10000
  class_weight: balanced

  # QUAL-specific metrics
  q1_mlflow_exp_name: 220913_114531_Q1_1000t
  q1_mlflow_run_id: c9882bab307e4452bd09166e4d059fcc
  q2_mlflow_exp_name: 220913_122406_Q2i_1000t
  q2_mlflow_run_id: c6f0a55bdb2c463fb159b0e3e8d42024
  q3_mlflow_exp_name: 220913_124429_Q3i_1000t
  q3_mlflow_run_id: 1cc2ead791d341cc8445317fbe9bf3ad
  qual_text_mlflow_exp_name: QUAL_manual
  qual_text_mlflow_run_id: e1a1cb95017a499b81f2335c0733ec48
  qual_fit_type: 'text_only' # text_only/submodels_only/simultaneous/text_first/simple_sum

train_tf:
  mlflow_dir: mlruns
  conda_yaml_path: './conda.yaml'
  mlflow_tracking_dir: ./mlruns
  mlflow_experiment_name: ${train_tf.target_var}_tf_manual
  train_path: ${split_train_test.train_path}
  text_var: comment
  target_var: Q1  
  qual_exclude_level4: False
  invert_target: False

  # augmentation options
  do_aug: True
  do_replacement: True
  aug_factor: 1.0 # float, the multiplier for the whole dataset
  match_factor: 1.0 # float, the fraction of the most frequent class that the rarer classes are upsampled to
  

  fit_final: True

  n_splits: 1
  test_size: 0.25
  random_state: 43

  model: bert
  # submodel: bert-base-uncased
  # submodel: allenai/scibert_scivocab_uncased
  submodel: emilyalsentzer/Bio_ClinicalBERT

  # st_args
  num_train_epochs: 1
  output_dir: tf_outputs
  overwrite_output_dir: True
  use_multiprocessing: False
  use_multiprocessing_for_evaluation: False
  learning_rate: 0.00004
  train_batch_size: 8
  save_eval_checkpoints: False
  save_model_every_epoch: False
  save_steps: -1
  max_seq_length: 256

  objective_metric: mean_balanced_accuracy
  

test:
  mlflow_dir: ${train.mlflow_dir}
  mlflow_source_experiment_name: QUAL_manual
  mlflow_run_id: da867755527246ad87cb1111f4fa1f51
  test_path: ${split_train_test.test_path}
  text_var: ${train.text_var}
  target_var: ${train.target_var}
  invert_target: ${train.invert_target}
  qual_exclude_level4: ${train.qual_exclude_level4}
  mlflow_target_experiment_name: ${train.target_var}_test
  conda_yaml_path: ${train.conda_yaml_path}
  posthoc: True
  n_top: 15

test_tf:
  mlflow_dir: ${train_tf.mlflow_dir}
  mlflow_tracking_dir: ${train_tf.mlflow_tracking_dir}
  model: ${train_tf.model}
  mlflow_source_experiment_name: Q1_tf_bio-clinicalbert_tpe_1000t_220925_235140
  mlflow_run_id: 60cc36a581b34e62b0814ac7f7169c49
  train_path: ${split_train_test.train_path}
  test_path: ${split_train_test.test_path}
  text_var: ${train_tf.text_var}
  target_var: ${train_tf.target_var}
  invert_target: ${train_tf.invert_target}
  qual_exclude_level4: ${train_tf.qual_exclude_level4}
  mlflow_target_experiment_name: ${train_tf.target_var}_tf_test
  conda_yaml_path: ${train_tf.conda_yaml_path}

word_clouds:
  mlflow_dir: ${train_tf.mlflow_dir}
  mlflow_tracking_dir: ${train_tf.mlflow_tracking_dir}
  model: ${train_tf.model}
  mlflow_source_experiment_name: QUAL_tf_bio-clinicalbert_tpe_1000t_220924_104547
  mlflow_run_id: 046f731d3c6b4590acc2b9154ebc0e01
  # mlflow_source_experiment_name: Q2i_tf_bio-clinicalbert_tpe_100t_220925_121844
  # mlflow_run_id: 52e6735eafa542238a1fda2ee07c3b08
  train_path: ${split_train_test.train_path}
  test_path: ${split_train_test.test_path}
  text_var: ${train_tf.text_var}
  target_var: ${train_tf.target_var}
  invert_target: ${train_tf.invert_target}

  word_weight_len_thresh: 75

  word_scores_label_target: LABEL_4
  word_scores_csv_path: reports/word_weights_${word_clouds.word_scores_label_target}_${word_clouds.mlflow_source_experiment_name}.csv
  word_cloud_pos_path: reports/word_cloud_pos_${word_clouds.word_scores_label_target}_${word_clouds.mlflow_source_experiment_name}.png
  word_cloud_neg_path: reports/word_cloud_neg_${word_clouds.word_scores_label_target}_${word_clouds.mlflow_source_experiment_name}.png

  wc_figsize_width: 10
  wc_figsize_height: 5
  wc_max_words: 500
  wc_count_thresh: 10
  wc_width: 800
  wc_height: 400
  wc_background_color: black
  wc_pos_colormap: Greens
  wc_neg_colormap: Reds
  wc_exclude_partwords: True

defaults:
  - override hydra/sweeper: optuna
  - override hydra/sweeper/sampler: tpe # random
  # - override hydra/launcher: joblib # 
  - override hydra/job_logging: colorlog
  - override hydra/hydra_logging: colorlog

hydra:
  sweeper:
    sampler:
      _target_: optuna.samplers.TPESampler
      seed: 247
      consider_prior: true
      prior_weight: 1.0
      consider_magic_clip: true
      consider_endpoints: false
      n_startup_trials: 30 # TODO
      n_ei_candidates: 24
      multivariate: false
      warn_independent_sampling: true
    _target_: hydra_plugins.hydra_optuna_sweeper.optuna_sweeper.OptunaSweeper
    direction: maximize
    study_name: test_study
    storage: null
    n_trials: 1000
    # max_failure_rate: 1.0
    n_jobs: 1
    params:
      train_tf.num_train_epochs: choice(1,2,3)
      train_tf.output_dir: tf_outputs
      train_tf.overwrite_output_dir: True
      train_tf.use_multiprocessing: False
      train_tf.use_multiprocessing_for_evaluation: False
      train_tf.learning_rate: interval(0.000004, 0.0004)
      train_tf.train_batch_size: choice(8,16,32)
      train_tf.do_replacement: choice(True, False)
      train_tf.aug_factor: interval(1.0, 2.0) # float, the multiplier for the whole dataset
      train_tf.match_factor: interval(0.5, 1.0)
      train_tf.mlflow_experiment_name: tf_sweep_testing
      train_tf.max_seq_length: 256

# hydra:
#   sweeper:
#     sampler:
#       seed: 43
#     direction: maximize
#     study_name: test_study
#     storage: null
#     n_trials: 100
#     n_jobs: 14
#     params:
#       train.mlflow_experiment_name: sweep_random_100_test_yes_vectors
#       train.model_c: choice(1,0.1,0.01,0.001,0.0001)
#       train.punct: choice(True, False)
#       train.pron: choice(True, False)
#       train.stop: choice(True, False)
#       train.lemma: choice(True, False)
#       train.ngram_min: 1
#       train.ngram_max: range(1,8)
#       train.max_df: interval(0.1, 1.0)
#       train.min_df: range(1,30)
#       train.token_count: choice(True, False)
#       train.pos_counts: choice(True, False)
#       train.ent_counts: choice(True, False)
#       train.vectors: choice(True, False)
#       train.class_weight: balanced,null
#       train.aug_factor: interval(1.0, 2.0)
#       train.match_factor: interval(0.25, 1.0)
#       train.spacy_prog: False
#       train.spacy_procs: 1





