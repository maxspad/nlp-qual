{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxspad/mambaforge/envs/nlp-qual-max/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from transformers_interpret import SequenceClassificationExplainer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_pipeline(username, prefix, model_name, device='cpu'):\n",
    "    p = tf.pipeline('text-classification', f'{username}/{prefix}-{model_name}', return_all_scores=True, device=device)\n",
    "    return p\n",
    "\n",
    "def load_data(data_folder):\n",
    "    df_train = pd.read_pickle(f'{data_folder}/train.pkl')\n",
    "    df_test = pd.read_pickle(f'{data_folder}/test.pkl')\n",
    "    df = pd.concat([df_train, df_test])\n",
    "    return df\n",
    "\n",
    "def clean_data(df : pd.DataFrame, p : tf.Pipeline, na_repl='blank', max_tokens=256, min_tokens=5):\n",
    "    print(f'Original df size: {df.shape}')\n",
    "\n",
    "    print(f'Filling NAN in comment with \"{na_repl}\"')\n",
    "    df['comment'] = df.comment.fillna(na_repl)\n",
    "\n",
    "    df['tf_toklen'] = [len(toks) for toks in p.tokenizer(df.comment.tolist())['input_ids']]\n",
    "    df = df[df['tf_toklen'] <= max_tokens]\n",
    "    print(f'Size after filtering comments longer than {max_tokens} tokens: {df.shape}')\n",
    "\n",
    "    df = df[df['tf_toklen'] > min_tokens]\n",
    "    print(f'Size after filtering comments shorter than {min_tokens} tokens: {df.shape}')\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_word_importances(comments : list[str], p : tf.Pipeline, relative_to: str):\n",
    "\n",
    "    explainer = SequenceClassificationExplainer(p.model, p.tokenizer)\n",
    "\n",
    "    word_imports = {}\n",
    "    for comment in tqdm(comments):\n",
    "        attribs = explainer(comment, class_name=relative_to)\n",
    "        for w, score in attribs:\n",
    "            try:\n",
    "                word_imports[w].append(score)\n",
    "            except KeyError:\n",
    "                word_imports[w] = [score]\n",
    "    return word_imports\n",
    "\n",
    "def save_word_importances(word_imports : dict, path : str):\n",
    "    print(f'Saving word importances to {path}')\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(word_imports, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxspad/mambaforge/envs/nlp-qual-max/lib/python3.9/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original df size: (2500, 46)\n",
      "Filling NAN in comment with \"blank\"\n",
      "Size after filtering comments longer than 256 tokens: (2453, 47)\n",
      "Size after filtering comments longer than 5 tokens: (2296, 47)\n"
     ]
    }
   ],
   "source": [
    "p = load_model_pipeline('maxspad','nlp-qual','qual')\n",
    "df = load_data('../data/processed/')\n",
    "df = clean_data(df, p, max_tokens=256, min_tokens=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2453.000000\n",
       "mean       42.207501\n",
       "std        45.608177\n",
       "min         3.000000\n",
       "25%        14.000000\n",
       "50%        25.000000\n",
       "75%        50.000000\n",
       "max       254.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_lens = pd.Series([len(toks) for toks in p.tokenizer(df.comment.tolist())['input_ids']])\n",
    "tok_lens.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "Calculating word importances for model q1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxspad/mambaforge/envs/nlp-qual-max/lib/python3.9/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original df size: (2500, 46)\n",
      "Filling NAN in comment with \"blank\"\n",
      "Size after filtering comments longer than 256 tokens: (2453, 47)\n",
      "Reference label LABEL_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2453 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2453/2453 [1:01:56<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving word importances to ../results/word_importances/q1_LABEL_2.pkl\n",
      "\n",
      "\n",
      "################################################################################\n",
      "Calculating word importances for model q2i\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxspad/mambaforge/envs/nlp-qual-max/lib/python3.9/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original df size: (2500, 46)\n",
      "Filling NAN in comment with \"blank\"\n",
      "Size after filtering comments longer than 256 tokens: (2453, 47)\n",
      "Reference label LABEL_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2453/2453 [1:01:12<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving word importances to ../results/word_importances/q2i_LABEL_0.pkl\n",
      "\n",
      "\n",
      "################################################################################\n",
      "Calculating word importances for model q3i\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxspad/mambaforge/envs/nlp-qual-max/lib/python3.9/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original df size: (2500, 46)\n",
      "Filling NAN in comment with \"blank\"\n",
      "Size after filtering comments longer than 256 tokens: (2453, 47)\n",
      "Reference label LABEL_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2453/2453 [57:44<00:00,  1.41s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving word importances to ../results/word_importances/q3i_LABEL_0.pkl\n",
      "\n",
      "\n",
      "################################################################################\n",
      "Calculating word importances for model qual\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxspad/mambaforge/envs/nlp-qual-max/lib/python3.9/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original df size: (2500, 46)\n",
      "Filling NAN in comment with \"blank\"\n",
      "Size after filtering comments longer than 256 tokens: (2453, 47)\n",
      "Reference label LABEL_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2453/2453 [59:32<00:00,  1.46s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving word importances to ../results/word_importances/qual_LABEL_1.pkl\n",
      "Reference label LABEL_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2453/2453 [59:26<00:00,  1.45s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving word importances to ../results/word_importances/qual_LABEL_3.pkl\n",
      "Reference label LABEL_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2453/2453 [1:00:39<00:00,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving word importances to ../results/word_importances/qual_LABEL_5.pkl\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "models = ['q1','q2i','q3i','qual']\n",
    "reference_labels = [['LABEL_2'],['LABEL_0'],['LABEL_0'],['LABEL_1','LABEL_3','LABEL_5']]\n",
    "data_dir = '../data/processed/'\n",
    "max_tokens = 255\n",
    "save_dir = '../results/word_importances'\n",
    "\n",
    "for model, ref_labs in zip(models, reference_labels):\n",
    "    print('#'*80)\n",
    "    print(f'Calculating word importances for model {model}')\n",
    "\n",
    "    p = load_model_pipeline('maxspad','nlp-qual',model)\n",
    "    \n",
    "    df = load_data('../data/processed/')\n",
    "    df = clean_data(df, p, max_tokens=256)\n",
    "    \n",
    "    for ref_lab in ref_labs:\n",
    "        print(f'Reference label {ref_lab}')\n",
    "        word_imports = get_word_importances(df.comment.tolist(), p, ref_lab)\n",
    "        save_word_importances(word_imports, f'{save_dir}/{model}_{ref_lab}.pkl')\n",
    "\n",
    "    print('\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-qual-max",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
